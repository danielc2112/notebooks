{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIMPANDO DADOS - UM EXEMPLO COM TWITTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a Coleta de dados envolve a sua limpeza para posterior pré-processamento (enriquecimento).\n",
    "\n",
    "Há quem coloque limpeza em pré-processamento, mas tanto faz onde se coloca ..precisa ser feito ..senão entramos em 'garbage in, garbage out'\n",
    "\n",
    "Uma limpeza eficaz pode permitir que até dados muito ruidosos se tornem úteis e tragam algum conhecimento.\n",
    "\n",
    "Este exemplo exibe os principais passos na limpeza de dados em fontes altamente desestruturadas -- mídias sociais.\n",
    "\n",
    "vejamos a nossa twitada candidato:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I luv my &lt;3 iphone &amp; it's great!! you're awsm apple. DisplayIsAwesome, sooo happppppy :) http://www.apple.com\n"
     ]
    }
   ],
   "source": [
    "orig_twit = \"I luv my &lt;3 iphone &amp; it's great!! you're awsm apple. DisplayIsAwesome, sooo happppppy :) http://www.apple.com\"\n",
    "\n",
    "print orig_twit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>Maravilha, né?\n",
    "\n",
    "Vamos ao trabalho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - **DECODIFICANDO** \n",
    "\n",
    "Texto pode estar em diferentes formatos de codificação -- como \"Latin-1\" ou 'UTF-8\", etc. Assim, para podermos melor analisar é necessário manter todos os dados em algum formato padrão.\n",
    "\n",
    "UTF-8 é bastante popular e recomendado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I luv my &lt;3 iphone &amp; it's great!! you're awsm apple. DisplayIsAwesome, sooo happppppy :) http://www.apple.com\n"
     ]
    }
   ],
   "source": [
    "twit = orig_twit.decode(\"utf8\").encode('ascii','ignore')\n",
    "\n",
    "print twit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "2 - **LIMPANDO HTML**\n",
    "\n",
    "Dados obtidos da web geralmente contém entidades em HTML, como &lt; &amp e etc. que ficam entranhados nos nossos dados.\n",
    "\n",
    "Podemos tirar estes com uso de **expressões regulares** sem muito esforço, mas no python por sorte há módulos que podem converter estas entidades em tags HTML normais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I luv my <3 iphone & it's great!! you're awsm apple. DisplayIsAwesome, sooo happppppy :) http://www.apple.com\n"
     ]
    }
   ],
   "source": [
    "import HTMLParser\n",
    "\n",
    "html_parser = HTMLParser.HTMLParser()\n",
    "\n",
    "twit = html_parser.unescape(twit)\n",
    "\n",
    "print twit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "3 - **APOSTROFES E CONTRAÇÕES**\n",
    "\n",
    "Se estivermos lidando com inglês (que permeia a web) uma boa estratégia é extrair as formas completas das contrações. Isso porém requer alguma desambiguação,que não veremos neste exemplo (e.g. it's vira 'it is' ou 'it has'?).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I luv my <3 iphone & it is great!! you are awsm apple. DisplayIsAwesome, sooo happppppy :) http://www.apple.com\n"
     ]
    }
   ],
   "source": [
    "## Dicionario enorme\n",
    "APPOSTOPHES = {u\"'s\" : u\" is\", u\"'re\" : u\" are\"}\n",
    "\n",
    "words = twit.split()\n",
    "\n",
    "for pattern in APPOSTOPHES:\n",
    "    for idx,word in enumerate(words):\n",
    "        if pattern in word:\n",
    "            tokens = word.split(pattern)\n",
    "            words[idx] = tokens[0] + APPOSTOPHES[pattern]\n",
    "\n",
    "reformed = \" \".join(words)\n",
    "\n",
    "print reformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "4 - **REMOVER STOP-WORDS**\n",
    "\n",
    "Quando a análise é (estritamente) estatística, devemos considerar a remoção das chamadas STOP-WORDS. \n",
    "\n",
    "STOP-WORDS são palavras frequentes que ocorrem em quase qualquer texto, quase qualquer frase, e.g. 'e', 'de', 'para', artigos, etc.\n",
    "\n",
    "5 - **REMOVER PONTUAÇÃO**\n",
    "\n",
    "Todas as pontuações devem ser tratadas (removidas, uniformizadas, ou ao menos identificadas e classificadas). Os principais delimitadores ('.';',';'?') devem ser retidos.\n",
    "\n",
    "6 - **REMOVER EXPRESSÕES**\n",
    "\n",
    "Comunicação textual em mídias sociais frequentemente exibe descrições de sentimento [chorando], [rindo], LOL, e etc.\n",
    "\n",
    "Dependendo do objetivo da sua análise, estas expressões não são úteis e devem ser removidas. Neste caso **expressões regulares** voltam a ser a principal ferramenta.\n",
    "\n",
    "7 - **PARTIR PALAVRAS**\n",
    "\n",
    "Novamente, texto digitado de forma casual e informal não seguem muitas regras, assim é comum a ocorrência de palavras e expressões (incluindo hashtags) não serem divididas por espaço. Algumas regras simples de regex podem aliviar o problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I luv my <3 iphone & it is great!! you are awsm apple.  Display Is Awesome, sooo happppppy :) http://www.apple.com\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "cleaned = \" \".join(re.findall('[A-Z][^A-Z]*', reformed))\n",
    "\n",
    "print cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "8 - **GÍRIAS**\n",
    "\n",
    "Se tivermos acesso a algum léxico (seja ele formal ou de gírias) podemos montar um dicionário normalizador -- há recursos para normalizar gírias em Inglês, porém nunca encontrei algum específico para Português."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love my <3 iphone & it is great!! you are awesome apple. Display Is Awesome, sooo happppppy :) http://www.apple.com\n"
     ]
    }
   ],
   "source": [
    "slang_norm = {\n",
    "    'luv':'love',\n",
    "    'awsm':'awesome',\n",
    "    # em tese teriamos um dicionario enorme!\n",
    "}\n",
    "\n",
    "tokens = cleaned.split()\n",
    "\n",
    "real_words = [slang_norm[token.lower()] if slang_norm.get(token) else token for token in tokens ]\n",
    "\n",
    "real_words = ' '.join(real_words)\n",
    "\n",
    "print real_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 - **PADRONIZAÇÃO**\n",
    "\n",
    "Para tornar palavras passíveis de análise, é necessário algum tipo de padronização i.e. 'adddoroooooo' deveria ser 'adoro'.\n",
    "\n",
    "Regras simples utilizando deduplicação de caracteres podem ser um ótimo passo inicial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love my <3 iphone & it is great!! you are awesome apple. Display Is Awesome, soo happy :) http://ww.apple.com\n"
     ]
    }
   ],
   "source": [
    "from itertools import groupby \n",
    "\n",
    "# notem que o 'soo' permanece duplicado ..a heuristice é útil \n",
    "# mas não resolve o problema todo!\n",
    "twit_final = ''.join(''.join(s)[:2] for _, s in groupby(real_words))\n",
    "\n",
    "print twit_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br> Este problema se torna mais fácil em Português, uma vez que não temos (que eu saiba!) palavras com a mesma letra duplicada e.g. 'soon', 'moon','reek'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>Estes são os principais passos a serem considerados durante a limpeza de dados textuais. \n",
    "\n",
    "Esta lista não é abrangente, mas busca dar visão sobre os desafios a serem encontrados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBS**: Vale ressaltar que nenhum destes passos é um *requerimento*. A natureza da tarefa sendo abordada ditará, primeiramente, o que deve ou não ser feito para alcançar algum resultado desejável de análise. \"A ferramenta certa para o trabalho certo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
