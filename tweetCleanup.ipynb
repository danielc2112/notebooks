{
 "metadata": {
  "name": "",
  "signature": "sha256:c080a8167f949890037e5b5332e3f6f404c22596616945f35722a18b4f9a203c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "LIMPANDO DADOS - UM EXEMPLO COM TWITTER"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "a Coleta de dados envolve a sua limpeza para posterior pr\u00e9-processamento (enriquecimento).\n",
      "\n",
      "H\u00e1 quem coloque limpeza em pr\u00e9-processamento, mas tanto faz onde se coloca ..precisa ser feito ..sen\u00e3o entramos em 'garbage in, garbage out'\n",
      "\n",
      "Uma limpeza eficaz pode permitir que at\u00e9 dados muito ruidosos se tornem \u00fateis e tragam algum conhecimento.\n",
      "\n",
      "Este exemplo exibe os principais passos na limpeza de dados em fontes altamente desestruturadas -- m\u00eddias sociais.\n",
      "\n",
      "vejamos a nossa twitada candidato:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "orig_twit = \"I luv my &lt;3 iphone &amp; it's great!! you're awsm apple. DisplayIsAwesome, sooo happppppy :) http://www.apple.com\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br><br>Maravilha, n\u00e9?\n",
      "\n",
      "Vamos ao trabalho."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1 - **DECODIFICANDO** \n",
      "\n",
      "Texto pode estar em diferentes formatos de codifica\u00e7\u00e3o -- como \"Latin-1\" ou 'UTF-8\", etc. Assim, para podermos melor analisar \u00e9 necess\u00e1rio manter todos os dados em algum formato padr\u00e3o.\n",
      "\n",
      "UTF-8 \u00e9 bastante popular e recomendado."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twit = orig_twit.decode(\"utf8\").encode('ascii','ignore')\n",
      "\n",
      "print twit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I luv my &lt;3 iphone &amp; it's great!! you're awsm apple. DisplayIsAwesome, sooo happppppy :) http://www.apple.com\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2 - **LIMPANDO HTML**\n",
      "\n",
      "Dados obtidos da web geralmente cont\u00e9m entidades em HTML, como &lt; &amp e etc. que ficam entranhados nos nossos dados.\n",
      "\n",
      "Podemos tirar estes com uso de **express\u00f5es regulares** sem muito esfor\u00e7o, mas no python por sorte h\u00e1 m\u00f3dulos que podem converter estas entidades em tags HTML normais."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import HTMLParser\n",
      "\n",
      "html_parser = HTMLParser.HTMLParser()\n",
      "\n",
      "twit = html_parser.unescape(twit)\n",
      "\n",
      "print twit\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I luv my <3 iphone & it's great!! you're awsm apple. DisplayIsAwesome, sooo happppppy :) http://www.apple.com\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br><br>\n",
      "3 - **APOSTROFES E CONTRA\u00c7\u00d5ES**\n",
      "\n",
      "Se estivermos lidando com ingl\u00eas (que permeia a web) uma boa estrat\u00e9gia \u00e9 extrair as formas completas das contra\u00e7\u00f5es. Isso por\u00e9m requer alguma desambigua\u00e7\u00e3o,que n\u00e3o veremos neste exemplo (e.g. it's vira 'it is' ou 'it has'?).\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Dicionario enorme\n",
      "APPOSTOPHES = {u\"'s\" : u\" is\", u\"'re\" : u\" are\"}\n",
      "\n",
      "words = twit.split()\n",
      "\n",
      "for pattern in APPOSTOPHES:\n",
      "    for idx,word in enumerate(words):\n",
      "        if pattern in word:\n",
      "            tokens = word.split(pattern)\n",
      "            words[idx] = tokens[0] + APPOSTOPHES[pattern]\n",
      "\n",
      "reformed = \" \".join(words)\n",
      "\n",
      "print reformed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I luv my <3 iphone & it is great!! you are awsm apple. DisplayIsAwesome, sooo happppppy :) http://www.apple.com\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br><br>\n",
      "4 - **REMOVER STOP-WORDS**\n",
      "\n",
      "Quando a an\u00e1lise \u00e9 (estritamente) estat\u00edstica, devemos considerar a remo\u00e7\u00e3o das chamadas STOP-WORDS. \n",
      "\n",
      "STOP-WORDS s\u00e3o palavras frequentes que ocorrem em quase qualquer texto, quase qualquer frase, e.g. 'e', 'de', 'para', artigos, etc.\n",
      "\n",
      "5 - **REMOVER PONTUA\u00c7\u00c3O**\n",
      "\n",
      "Todas as pontua\u00e7\u00f5es devem ser tratadas (removidas, uniformizadas, ou ao menos identificadas e classificadas). Os principais delimitadores ('.';',';'?') devem ser retidos.\n",
      "\n",
      "6 - **REMOVER EXPRESS\u00d5ES**\n",
      "\n",
      "Comunica\u00e7\u00e3o textual em m\u00eddias sociais frequentemente exibe descri\u00e7\u00f5es de sentimento [chorando], [rindo], LOL, e etc.\n",
      "\n",
      "Dependendo do objetivo da sua an\u00e1lise, estas express\u00f5es n\u00e3o s\u00e3o \u00fateis e devem ser removidas. Neste caso **express\u00f5es regulares** voltam a ser a principal ferramenta.\n",
      "\n",
      "7 - **PARTIR PALAVRAS**\n",
      "\n",
      "Novamente, texto digitado de forma casual e informal n\u00e3o seguem muitas regras, assim \u00e9 comum a ocorr\u00eancia de palavras e express\u00f5es (incluindo hashtags) n\u00e3o serem divididas por espa\u00e7o. Algumas regras simples de regex podem aliviar o problema."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "cleaned = \" \".join(re.findall('[A-Z][^A-Z]*', reformed))\n",
      "\n",
      "print cleaned"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I luv my <3 iphone & it is great!! you are awsm apple.  Display Is Awesome, sooo happppppy :) http://www.apple.com\n"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br><br>\n",
      "8 - **G\u00cdRIAS**\n",
      "\n",
      "Se tivermos acesso a algum l\u00e9xico (seja ele formal ou de g\u00edrias) podemos montar um dicion\u00e1rio normalizador -- h\u00e1 recursos para normalizar g\u00edrias em Ingl\u00eas, por\u00e9m nunca encontrei algum espec\u00edfico para Portugu\u00eas."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "slang_norm = {\n",
      "    'luv':'love',\n",
      "    'awsm':'awesome',\n",
      "    # em tese teriamos um dicionario enorme!\n",
      "}\n",
      "\n",
      "tokens = cleaned.split()\n",
      "\n",
      "real_words = [slang_norm[token.lower()] if slang_norm.get(token) else token for token in tokens ]\n",
      "\n",
      "real_words = ' '.join(real_words)\n",
      "\n",
      "print real_words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I love my <3 iphone & it is great!! you are awesome apple. Display Is Awesome, sooo happppppy :) http://www.apple.com\n"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "9 - **PADRONIZA\u00c7\u00c3O**\n",
      "\n",
      "Para tornar palavras pass\u00edveis de an\u00e1lise, \u00e9 necess\u00e1rio algum tipo de padroniza\u00e7\u00e3o i.e. 'adddoroooooo' deveria ser 'adoro'.\n",
      "\n",
      "Regras simples utilizando deduplica\u00e7\u00e3o de caracteres podem ser um \u00f3timo passo inicial:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import groupby \n",
      "\n",
      "# notem que o 'soo' permanece duplicado ..a heuristice \u00e9 \u00fatil \n",
      "# mas n\u00e3o resolve o problema todo!\n",
      "twit_final = ''.join(''.join(s)[:2] for _, s in groupby(real_words))\n",
      "\n",
      "print twit_final"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "I love my <3 iphone & it is great!! you are awesome apple. Display Is Awesome, soo happy :) http://ww.apple.com\n"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br><br> Este problema se torna mais f\u00e1cil em Portugu\u00eas, uma vez que n\u00e3o temos (que eu saiba!) palavras com a mesma letra duplicada e.g. 'soon', 'moon','reek'."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br><br>Estes s\u00e3o os principais passos a serem considerados durante a limpeza de dados textuais. \n",
      "\n",
      "Esta lista n\u00e3o \u00e9 abrangente, mas busca dar vis\u00e3o sobre os desafios a serem encontrados"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**OBS**: Vale ressaltar que nenhum destes passos \u00e9 um *requerimento*. A natureza da tarefa sendo abordada ditar\u00e1, primeiramente, o que deve ou n\u00e3o ser feito para alcan\u00e7ar algum resultado desej\u00e1vel de an\u00e1lise. \"A ferramenta certa para o trabalho certo\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}