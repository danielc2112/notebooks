{
 "metadata": {
  "name": "",
  "signature": "sha256:179373c81dcfaab3ec3654ea5eac91cd2d9cd90fd09126f62502a2dd76103af3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Topic Models"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "_Topic models_ s\u00e3o a suite de algoritmos que permitem descobrir a estrutura subjacente a uma cole\u00e7\u00e3o de documentos. Tendo em vista o atual acesso a massas enormes de documentos de todos os tipos, torna-se necess\u00e1rio o uso de ferramentas"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nossa tarefa \u00e9 achar duas matrizes: $\\mathbf{P}$ (de tamanho $|U| \\times K$) e $\\mathbf{Q}$ (de tamanho $|D| \\times K$ matrix) tal que seu produto se aproxime de $\\mathbf{R}$: \n",
      "$$\\mathbf{R} \\approx \\mathbf{P} \\times \\mathbf{Q}^T = \\hat{\\mathbf{R}}$$\n",
      "\n",
      "Desta forma, cada fileira de $\\mathbf{P}$ representa a for\u00e7a de associa\u00e7\u00e3o entre um termo e as features (t\u00f3picos). Similarmente, cada fileira de $\\mathbf{Q}$ representa a for\u00e7a de associa\u00e7\u00e3o entre uma palavra e as features.\n",
      "\n",
      "Para ver o valor associado a um item $d_j$ por $u_i$ podemos calcular o produto escalar dos vetores correspondentes a $u_i$ e $d_j$:\n",
      "$$ \\hat{r}_{ij} = p_i^T q_j = \\sum_{k=1}^{k}p_{ik}q_{kj} $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Agora precisamos de uma forma para obter $\\mathbf{P}$ e $\\mathbf{Q}$. Uma das formas \u00e9: i) inicializar ambas as matrizes com alguns valores; ii) calcular a 'diferen\u00e7a' dos seus produtos a $\\mathbf{R}$; iii) tentar minimizar esta diferen\u00e7a em itera\u00e7\u00f5es\n",
      "\n",
      "Este m\u00e9todo \u00e9 comumente chamado de _gradient descent_, a diferen\u00e7a (do passo ii, chamada de erro entre o estimado e o real, pode ser calculada da seguinte forma:\n",
      "$$e_{ij}^2=(r_{ij}-\\hat{r}_{ij})^2 = (r_{ij} - \\sum_{k=1}^k{p_{ik}q_{kj}})^2$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vale considerar o erro quadr\u00e1tico pois o valor real pode estar acima ou abaixo do estimado.\n",
      "\n",
      "Para minimizar o erro, temos que saber em qual dire\u00e7\u00e3o precisamos modificar os valores de $p_{ik}$ e $q_{kj}$. Isto \u00e9, precisamos saber o _gradiente_ nos valores atuais. \n",
      "\n",
      "Assim, diferenciamos a equa\u00e7\u00e3o acima com respeito a ambas as vari\u00e1veis separadamente:\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>$$\\frac{\\partial}{\\partial p_{ik}}e^2_{ij} = -2(r_{ij}-\\hat{r}_{ij})(q_{kj}) = -2e_{ij}q_{kj}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>$$\\frac{\\partial}{\\partial q_{kj}}e^2_{ij} = -2(r_{ij}-\\hat{r}_{ij})(p_{ik}) = -2e_{ij}p_{ik}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br><br>Com este resultado podemos formular regras de itera\u00e7\u00e3o para $p_{ik}$ e $q_{kj}$\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$p'_{ik} = p_{ik} + \\alpha\\frac{\\partial}{\\partial p_{ik}}e^2_{ij} = p_{ik} + 2\\alpha e_{ij}q_{kj}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$q'_{kj} = q_{kj} + \\alpha\\frac{\\partial}{\\partial q_{kj}}e^2_{ij} = q_{kj} + 2\\alpha e_{ij}p_{ik}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>Alfa aqui \u00e9 um constante que determina a taxa de aproxim\u00e7\u00e3o do m\u00ednimo. \u00c9 aconselh\u00e1vel escolher um valor pequeno pois, se for grande demais, arriscamos ficar oscilando em volta do ponto m\u00ednimo."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br><br>Assim, como resultado, temos $\\mathbf{P}$ de vetores-base, cujas colunas s\u00e3o nossos **t\u00f3picos** e $\\mathbf{Q}$ que mostra as filia\u00e7\u00f5es dos documentos aos t\u00f3picos."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Regulariza\u00e7\u00e3o e Outras Estrat\u00e9gias"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "O algoritmo apresentado \u00e9 o b\u00e1sico para se fatorizar uma matriz. H\u00e1 muitos m\u00e9todos para comlicar (e em tese melhorar).\n",
      "\n",
      "Uma extens\u00e3o comum \u00e9 introduzir um fator de regulariza\u00e7\u00e3o para evitar _overfitting_. Podemos adicionar um par\u00e2metro $\\beta$ e modificar o c\u00e1lculo do erro quadr\u00e1tico, assim:\n",
      "$$e_{ij}^2 = (r_{ij} - \\sum_{k=1}^K{p_{ik}q_{kj}})^2 + \\frac{\\beta}{2} \\sum_{k=1}^K{(||P||^2 + ||Q||^2)}$$\n",
      "\n",
      "Desta forma o novo par\u00e2metro $\\beta$ \u00e9 usado para controlar as magnitudes dos vetores, de tal forma que $\\mathbf{P}$ e $\\mathbf{Q}$ possam resultar em boas aproxima\u00e7\u00f5es de $\\mathbf{R}$ sem precisarem conter n\u00fameros grandes. Na pr\u00e1tica colocamos $\\beta$ em torno de 0.02\n",
      "\n",
      "A nova regra de itera\u00e7\u00e3o fica ent\u00e3o:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ p'_{ik} = p_{ik} + \\alpha \\frac{\\partial}{\\partial p_{ik}}e_{ij}^2 = p_{ik} + \\alpha(2 e_{ij} q_{kj} - \\beta p_{ik} ) $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ q'_{kj} = q_{kj} + \\alpha \\frac{\\partial}{\\partial q_{kj}}e_{ij}^2 = q_{kj} + \\alpha(2 e_{ij} p_{ik} - \\beta q_{kj} ) $$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Implementando"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "###############################################################################\n",
      "\n",
      "\n",
      "def matrix_factorization(R, P, Q, K, steps=500, alpha=0.0002, beta=0.02):\n",
      "    \"\"\"\n",
      "    @INPUT:\n",
      "        R     : a matriz a ser fatorizada, dim. N x M\n",
      "        P     : uma matriz inicial de dim. N x K\n",
      "        Q     : uma matriz inicial de dim. M x K\n",
      "        K     : o n\u00famero de features latentes (neste caso t\u00f3picos)\n",
      "        steps : o n\u00famero m\u00e1ximo de itera\u00e7\u00f5es a maximizar, depois para\n",
      "        alpha : a taxa de aprendizado\n",
      "        beta  : parametro de regulariza\u00e7\u00e3o\n",
      "    @OUTPUT:\n",
      "        as matrizes finais P and Q\n",
      "    \"\"\"\n",
      "    Q = Q.T \n",
      "    \n",
      "    # OBS: existem implementa\u00e7\u00f5es MapReduce otimizadas\n",
      "    for step in xrange(steps):\n",
      "        for i in xrange(len(R)):\n",
      "            for j in xrange(len(R[i])):\n",
      "                \n",
      "                if R[i][j] > 0:\n",
      "                    \n",
      "                    eij = R[i][j] - numpy.dot(P[i,:], Q[:,j])\n",
      "                    \n",
      "                    for k in xrange(K):\n",
      "                \n",
      "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
      "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
      "        \n",
      "        eR = numpy.dot(P,Q)\n",
      "        e = 0\n",
      "        for i in xrange(len(R)):\n",
      "            for j in xrange(len(R[i])):\n",
      "                if R[i][j] > 0:\n",
      "                    e = e + pow(R[i][j] - numpy.dot(P[i,:],Q[:,j]), 2)\n",
      "                    for k in xrange(K):\n",
      "                        e = e + (beta/2) * ( pow(P[i][k],2) + pow(Q[k][j],2) )\n",
      "        if e < 0.001:\n",
      "            break\n",
      "    return P, Q.T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br><br>Vamos testar? ..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "R = [\n",
      "     [5,3,0,1],\n",
      "     [4,0,0,1],\n",
      "     [1,1,0,5],\n",
      "     [1,0,0,4],\n",
      "     [0,1,5,4],\n",
      "    ]\n",
      "\n",
      "R = numpy.array(R)\n",
      "\n",
      "N = len(R)\n",
      "M = len(R[0])\n",
      "K = 2\n",
      "\n",
      "P = numpy.random.rand(N,K)\n",
      "Q = numpy.random.rand(M,K)\n",
      "\n",
      "nP, nQ = matrix_factorization(R, P, Q, K)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nR = numpy.dot(nP, nQ.T)\n",
      "\n",
      "print nR"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 2.77187556  1.83057671  1.4769508   2.80751545]\n",
        " [ 2.43195422  1.4715061   1.42761386  2.60784541]\n",
        " [ 2.47573409  1.56187622  1.39076158  2.58614644]\n",
        " [ 2.02323458  1.28749112  1.12571209  2.10155449]\n",
        " [ 2.83665738  1.598853    1.78026805  3.16811296]]\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d0 = \"\"\"Python is a 2000 made-for-TV horror movie directed by Richard\n",
      "Clabaugh. The film features several cult favorite actors, including William\n",
      "Zabka of The Karate Kid fame, Wil Wheaton, Casper Van Dien, Jenny McCarthy,\n",
      "Keith Coogan, Robert Englund (best known for his role as Freddy Krueger in the\n",
      "A Nightmare on Elm Street series of films), Dana Barron, David Bowe, and Sean\n",
      "Whalen. The film concerns a genetically engineered snake, a python, that\n",
      "escapes and unleashes itself on a small town. It includes the classic final\n",
      "girl scenario evident in films like Friday the 13th. It was filmed in Los Angeles,\n",
      " California and Malibu, California. Python was followed by two sequels: Python\n",
      " II (2002) and Boa vs. Python (2004), both also made-for-TV films.\"\"\"\n",
      "\n",
      "d1 = \"\"\"Python is a genus of\n",
      "nonvenomous pythons found in Africa and Asia. Currently, 7 species are\n",
      "recognised. A member of this genus, P. reticulatus, is among the longest\n",
      "snakes known. This snake is also very scary and I never want to see one up close. \n",
      "Which is scariest, pythons, sharks or ninjas?\"\"\"\n",
      "\n",
      "d2 = \"\"\"The Colt Python is a .357 Magnum caliber revolver formerly\n",
      "manufactured by Colt's Manufacturing Company of Hartford, Connecticut.\n",
      "It is sometimes referred to as a \"Combat Magnum\". It was first introduced\n",
      "in 1955, the same year as Smith &amp; Wesson's M29 .44 Magnum. The now discontinued\n",
      "Colt Python targeted the premium revolver market segment. Some firearm\n",
      "collectors and writers such as Jeff Cooper, Ian V. Hogg, Chuck Hawks, Leroy\n",
      "Thompson, Renee Smeets and Martin Dougherty have described the Python as the\n",
      "finest production revolver ever made.\"\"\"\n",
      "\n",
      "#d3 = \"\"\"I am a truly small text\"\"\"\n",
      "d3 = \"\"\"The fossil record of snakes is relatively poor because snake skeletons \n",
      "are typically small and fragile making fossilization uncommon. Fossils readily \n",
      "identifiable as snakes (though often retaining hind limbs) first appear in the \n",
      "fossil record during the Cretaceous period. The earliest known true snake \n",
      "fossils (members of the crown group Serpentes) come from the marine simoliophiids, \n",
      "the oldest of which is the Late Cretaceous (Cenomanian age) Haasiophis terrasanctus,\n",
      "dated to between 112 and 94 million years old. Based on comparative anatomy, there \n",
      "is consensus that snakes descended from lizards. Pythons and boas\u2014primitive \n",
      "groups among modern snakes\u2014have vestigial hind limbs: tiny, clawed digits known as anal \n",
      "spurs, which are used to grasp during mating. The families Leptotyphlopidae \n",
      "and Typhlopidae also possess remnants of the pelvic girdle, appearing as horny projections \n",
      "when visible.\"\"\"\n",
      "\n",
      "d4 = \"\"\"The potato is a starchy, tuberous crop from the perennial nightshade \n",
      "Solanum tuberosum L. The word \"potato\" may refer either to the plant itself \n",
      "or to the edible tuber. In the Andes, where the species is indigenous, there\n",
      "are some other closely related cultivated potato species. Potatoes were introduced\n",
      "outside the Andes region approximately four centuries ago, and have since \n",
      "become an integral part of much of the world's food supply. It is the world's \n",
      "fourth-largest food crop, following maize, wheat, and rice.\"\"\"\n",
      "\n",
      "corpus1 = [d0,d1,d2,d3,d4]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br><br>Reusando a fun\u00e7\u00e3o clean:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clean(doc):\n",
      "    #doc = doc.lower()\n",
      "    doc = doc.replace('.',' ')\n",
      "    doc = doc.replace('-', ' ')\n",
      "    doc = doc.replace(',',' ')\n",
      "    doc = doc.replace('?',' ')\n",
      "    doc = doc.replace(')',' ')\n",
      "    doc = doc.replace('(',' ')\n",
      "    \n",
      "    doc = doc.replace(' the ',' ')\n",
      "    doc = doc.replace(' of ',' ')\n",
      "    doc = doc.replace(' is ',' ')\n",
      "    doc = doc.replace(' and ',' ')\n",
      "    doc = doc.replace(' a ',' ')\n",
      "    doc = doc.replace(' on ',' ')\n",
      "    doc = doc.replace(' by ',' ')\n",
      "    doc = doc.replace(' in ',' ')\n",
      "    doc = doc.replace(' for ',' ')\n",
      "    doc = doc.replace(' it ',' ')\n",
      "    doc = doc.replace(' as ',' ')\n",
      "    \n",
      "    for _ in range(10):\n",
      "        doc = doc.replace('  ',' ')\n",
      "    return doc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction import stop_words\n",
      "\n",
      "def clean2(doc):\n",
      "    for word in doc.split():\n",
      "        if word in stop_words.ENGLISH_STOP_WORDS:\n",
      "            doc = doc.replace(' '+word+' ',' ')\n",
      "    return doc\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_matrix(corpus):\n",
      "    matrix = {}\n",
      "    for idx,doc in enumerate(corpus):\n",
      "        \n",
      "        doc = clean2(doc)\n",
      "        \n",
      "        for term in doc.split():\n",
      "            if not matrix.get(term):\n",
      "                matrix[term] = [0] * len(corpus)\n",
      "            matrix[term][idx] = matrix[term][idx] + 1\n",
      "    return matrix.keys(), matrix.values()\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run(corpus):\n",
      "    feature_names, df_matrix = make_matrix(corpus)\n",
      "\n",
      "    R = numpy.array(df_matrix)\n",
      "    N = len(R)\n",
      "    M = len(R[0])\n",
      "    K = 3\n",
      "    n_top_words = 20\n",
      "\n",
      "    P = numpy.random.rand(N,K)\n",
      "    Q = numpy.random.rand(M,K)\n",
      "\n",
      "    print 'P:',P.shape\n",
      "    print 'Q:',Q.shape\n",
      "    print 'palavras', len(feature_names)\n",
      "    nP, nQ = matrix_factorization(R, P, Q, K)\n",
      "\n",
      "    print 'components shape: ', nP.shape\n",
      "\n",
      "\n",
      "    for idx,topic in enumerate(nP.T):\n",
      "        print '\\nT\u00f3pico', idx\n",
      "\n",
      "        tmp = topic.argsort()[:-n_top_words - 1:-1]\n",
      "        for word_idx in tmp:\n",
      "            print feature_names[word_idx],\n",
      "        print '\\n'\n",
      "       "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run(corpus1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "P: (283, 3)\n",
        "Q: (5, 3)\n",
        "palavras 283\n",
        "components shape: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (283, 3)\n",
        "\n",
        "T\u00f3pico 0\n",
        "snakes record Colt's films perennial features II Cretaceous terrasanctus, concerns Magnum\". visible. fossilization \"Combat 13th. comparative movie families David old. \n",
        "\n",
        "\n",
        "T\u00f3pico 1\n",
        "Python Cretaceous hind Andes, following spurs, Hogg, Leptotyphlopidae Dougherty town. close. films), Haasiophis reticulatus, anal Cooper, Renee The Pythons A \n",
        "\n",
        "\n",
        "T\u00f3pico 2\n",
        "Python revolver snakes Wheaton, crop, closely Leroy tuberous years food descended member and Street poor Typhlopidae when python, lizards. grasp \n",
        "\n"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import fetch_20newsgroups\n",
      "\n",
      "\n",
      "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
      "\n",
      "corpus2 = dataset.data[:10]\n",
      "\n",
      "run(corpus2)\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "P: (608, 3)\n",
        "Q: (10, 3)\n",
        "palavras 608\n",
        "components shape: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (608, 3)\n",
        "\n",
        "T\u00f3pico 0\n",
        "I ? The the U.S. sort cache Israels know Flintstone's maybe hates Or, easy enough Jimmy. elapsed LET'S end is. \n",
        "\n",
        "\n",
        "T\u00f3pico 1\n",
        "? work How IIsi The street I say !QCiUk+ZmEf)IYI&bqMEffkT5bB`JhYl2K[0PXVe0B@@2*@Uam121D`A`h+cC)Xl caches. something? fairly letter Chewables! drive eventually Keith speedup used Jim. \n",
        "\n",
        "\n",
        "T\u00f3pico 2\n",
        "U.S. ? a the like work cache. question mustard, old allowed Your pepper, wondering biased 40%. israelis. will RANGERS!!!!! Magician_, \n",
        "\n"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}