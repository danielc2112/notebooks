{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Topic models_ são a suite de algoritmos que permitem descobrir a estrutura subjacente a uma coleção de documentos. Tendo em vista o atual acesso a massas enormes de documentos de todos os tipos, torna-se necessário o uso de ferramentas. Oprincipal algoritmo determinístico usado é Non-negative Matrix Factorization, que veremos aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa tarefa é achar duas matrizes: $\\mathbf{P}$ (de tamanho $|U| \\times K$) e $\\mathbf{Q}$ (de tamanho $|D| \\times K$ matrix) tal que seu produto se aproxime de $\\mathbf{R}$: \n",
    "$$\\mathbf{R} \\approx \\mathbf{P} \\times \\mathbf{Q}^T = \\hat{\\mathbf{R}}$$\n",
    "\n",
    "Desta forma, cada fileira de $\\mathbf{P}$ representa a força de associação entre um termo e as features (tópicos). Similarmente, cada fileira de $\\mathbf{Q}$ representa a força de associação entre uma palavra e as features.\n",
    "\n",
    "Para ver o valor associado a um item $d_j$ por $u_i$ podemos calcular o produto escalar dos vetores correspondentes a $u_i$ e $d_j$:\n",
    "$$ \\hat{r}_{ij} = p_i^T q_j = \\sum_{k=1}^{k}p_{ik}q_{kj} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora precisamos de uma forma para obter $\\mathbf{P}$ e $\\mathbf{Q}$. Uma das formas é: i) inicializar ambas as matrizes com alguns valores; ii) calcular a 'diferença' dos seus produtos a $\\mathbf{R}$; iii) tentar minimizar esta diferença em iterações\n",
    "\n",
    "Este método é comumente chamado de _gradient descent_, a diferença (do passo ii, chamada de erro entre o estimado e o real, pode ser calculada da seguinte forma:\n",
    "$$e_{ij}^2=(r_{ij}-\\hat{r}_{ij})^2 = (r_{ij} - \\sum_{k=1}^k{p_{ik}q_{kj}})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale considerar o erro quadrático pois o valor real pode estar acima ou abaixo do estimado.\n",
    "\n",
    "Para minimizar o erro, temos que saber em qual direção precisamos modificar os valores de $p_{ik}$ e $q_{kj}$. Isto é, precisamos saber o _gradiente_ nos valores atuais. \n",
    "\n",
    "Assim, diferenciamos a equação acima com respeito a ambas as variáveis separadamente:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>$$\\frac{\\partial}{\\partial p_{ik}}e^2_{ij} = -2(r_{ij}-\\hat{r}_{ij})(q_{kj}) = -2e_{ij}q_{kj}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>$$\\frac{\\partial}{\\partial q_{kj}}e^2_{ij} = -2(r_{ij}-\\hat{r}_{ij})(p_{ik}) = -2e_{ij}p_{ik}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>Com este resultado podemos formular regras de iteração para $p_{ik}$ e $q_{kj}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p'_{ik} = p_{ik} + \\alpha\\frac{\\partial}{\\partial p_{ik}}e^2_{ij} = p_{ik} + 2\\alpha e_{ij}q_{kj}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$q'_{kj} = q_{kj} + \\alpha\\frac{\\partial}{\\partial q_{kj}}e^2_{ij} = q_{kj} + 2\\alpha e_{ij}p_{ik}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Alfa aqui é um constante que determina a taxa de aproximção do mínimo. É aconselhável escolher um valor pequeno pois, se for grande demais, arriscamos ficar oscilando em volta do ponto mínimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>Assim, como resultado, temos $\\mathbf{P}$ de vetores-base, cujas colunas são nossos **tópicos** e $\\mathbf{Q}$ que mostra as filiações dos documentos aos tópicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularização e Outras Estratégias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "O algoritmo apresentado é o básico para se fatorizar uma matriz. Há muitos métodos para comlicar (e em tese melhorar).\n",
    "\n",
    "Uma extensão comum é introduzir um fator de regularização para evitar _overfitting_. Podemos adicionar um parâmetro $\\beta$ e modificar o cálculo do erro quadrático, assim:\n",
    "$$e_{ij}^2 = (r_{ij} - \\sum_{k=1}^K{p_{ik}q_{kj}})^2 + \\frac{\\beta}{2} \\sum_{k=1}^K{(||P||^2 + ||Q||^2)}$$\n",
    "\n",
    "Desta forma o novo parâmetro $\\beta$ é usado para controlar as magnitudes dos vetores, de tal forma que $\\mathbf{P}$ e $\\mathbf{Q}$ possam resultar em boas aproximações de $\\mathbf{R}$ sem precisarem conter números grandes. Na prática colocamos $\\beta$ em torno de 0.02\n",
    "\n",
    "A nova regra de iteração fica então:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ p'_{ik} = p_{ik} + \\alpha \\frac{\\partial}{\\partial p_{ik}}e_{ij}^2 = p_{ik} + \\alpha(2 e_{ij} q_{kj} - \\beta p_{ik} ) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ q'_{kj} = q_{kj} + \\alpha \\frac{\\partial}{\\partial q_{kj}}e_{ij}^2 = q_{kj} + \\alpha(2 e_{ij} p_{ik} - \\beta q_{kj} ) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "def matrix_factorization(R, P, Q, K, steps=500, alpha=0.0002, beta=0.02):\n",
    "    \"\"\"\n",
    "    @INPUT:\n",
    "        R     : a matriz a ser fatorizada, dim. N x M\n",
    "        P     : uma matriz inicial de dim. N x K\n",
    "        Q     : uma matriz inicial de dim. M x K\n",
    "        K     : o número de features latentes (neste caso tópicos)\n",
    "        steps : o número máximo de iterações a maximizar, depois para\n",
    "        alpha : a taxa de aprendizado\n",
    "        beta  : parametro de regularização\n",
    "    @OUTPUT:\n",
    "        as matrizes finais P and Q\n",
    "    \"\"\"\n",
    "    Q = Q.T \n",
    "    \n",
    "    # OBS: existem implementações MapReduce otimizadas\n",
    "    for step in xrange(steps):\n",
    "        for i in xrange(len(R)):\n",
    "            for j in xrange(len(R[i])):\n",
    "                \n",
    "                if R[i][j] > 0:\n",
    "                    \n",
    "                    eij = R[i][j] - numpy.dot(P[i,:], Q[:,j])\n",
    "                    \n",
    "                    for k in xrange(K):\n",
    "                \n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "        \n",
    "        eR = numpy.dot(P,Q)\n",
    "        e = 0\n",
    "        for i in xrange(len(R)):\n",
    "            for j in xrange(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow(R[i][j] - numpy.dot(P[i,:],Q[:,j]), 2)\n",
    "                    for k in xrange(K):\n",
    "                        e = e + (beta/2) * ( pow(P[i][k],2) + pow(Q[k][j],2) )\n",
    "        if e < 0.001:\n",
    "            break\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>Vamos testar? ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R = [\n",
    "     [5,3,0,1],\n",
    "     [4,0,0,1],\n",
    "     [1,1,0,5],\n",
    "     [1,0,0,4],\n",
    "     [0,1,5,4],\n",
    "    ]\n",
    "\n",
    "R = numpy.array(R)\n",
    "\n",
    "N = len(R)\n",
    "M = len(R[0])\n",
    "K = 3\n",
    "\n",
    "P = numpy.random.rand(N,K)\n",
    "Q = numpy.random.rand(M,K)\n",
    "\n",
    "nP, nQ = matrix_factorization(R, P, Q, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.81908515  2.06486017  2.83367564  2.79846492]\n",
      " [ 2.15339626  0.81951634  1.9735694   2.45714189]\n",
      " [ 2.42067177  1.02433082  2.24328641  2.70449595]\n",
      " [ 2.40015571  1.06536266  2.24087229  2.70775346]\n",
      " [ 3.55726406  1.91138659  3.39998631  3.81530104]]\n"
     ]
    }
   ],
   "source": [
    "nR = numpy.dot(nP, nQ.T)\n",
    "\n",
    "print nR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d0 = \"\"\"Python is a 2000 made-for-TV horror movie directed by Richard\n",
    "Clabaugh. The film features several cult favorite actors, including William\n",
    "Zabka of The Karate Kid fame, Wil Wheaton, Casper Van Dien, Jenny McCarthy,\n",
    "Keith Coogan, Robert Englund (best known for his role as Freddy Krueger in the\n",
    "A Nightmare on Elm Street series of films), Dana Barron, David Bowe, and Sean\n",
    "Whalen. The film concerns a genetically engineered snake, a python, that\n",
    "escapes and unleashes itself on a small town. It includes the classic final\n",
    "girl scenario evident in films like Friday the 13th. It was filmed in Los Angeles,\n",
    " California and Malibu, California. Python was followed by two sequels: Python\n",
    " II (2002) and Boa vs. Python (2004), both also made-for-TV films.\"\"\"\n",
    "\n",
    "d1 = \"\"\"Python is a phylum of\n",
    "nonvenomous pythons found in Africa and Asia. Currently, 7 species are\n",
    "recognised. A member of this genus, P. reticulatus, is among the longest\n",
    "snakes known. This snake is also very scary and I never want to see one up close. \n",
    "Which is scariest, pythons, sharks or ninjas?\"\"\"\n",
    "\n",
    "d2 = \"\"\"The Colt Python is a .357 Magnum caliber revolver formerly\n",
    "manufactured by Colt's Manufacturing Company of Hartford, Connecticut.\n",
    "It is sometimes referred to as a \"Combat Magnum\". It was first introduced\n",
    "in 1955, the same year as Smith &amp; Wesson's M29 .44 Magnum. The now discontinued\n",
    "Colt Python targeted the premium revolver market segment. Some firearm\n",
    "collectors and writers such as Jeff Cooper, Ian V. Hogg, Chuck Hawks, Leroy\n",
    "Thompson, Renee Smeets and Martin Dougherty have described the Python as the\n",
    "finest production revolver ever made.\"\"\"\n",
    "\n",
    "#d3 = \"\"\"I am a truly small text\"\"\"\n",
    "d3 = \"\"\"The fossil record of snakes is relatively poor because snake skeletons \n",
    "are typically small and fragile making fossilization uncommon. Fossils readily \n",
    "identifiable as snakes (though often retaining hind limbs) first appear in the \n",
    "fossil record during the Cretaceous period. The earliest known true snake \n",
    "fossils (members of the crown group Serpentes) come from the marine simoliophiids, \n",
    "the oldest of which is the Late Cretaceous (Cenomanian age) Haasiophis terrasanctus,\n",
    "dated to between 112 and 94 million years old. Based on comparative anatomy, there \n",
    "is consensus that snakes descended from lizards. Pythons and boas—primitive \n",
    "groups among modern snakes—have vestigial hind limbs: tiny, clawed digits known as anal \n",
    "spurs, which are used to grasp during mating. The families Leptotyphlopidae \n",
    "and Typhlopidae also possess remnants of the pelvic girdle, appearing as horny projections \n",
    "when visible.\"\"\"\n",
    "\n",
    "d4 = \"\"\"The potato is a starchy, tuberous crop from the perennial nightshade \n",
    "Solanum tuberosum L. The word \"potato\" may refer either to the plant itself \n",
    "or to the edible tuber. In the Andes, where the species is indigenous, there\n",
    "are some other closely related cultivated potato species. Potatoes were introduced\n",
    "outside the Andes region approximately four centuries ago, and have since \n",
    "become an integral part of much of the world's food supply. It is the world's \n",
    "fourth-largest food crop, following maize, wheat, and rice.\"\"\"\n",
    "\n",
    "corpus1 = [d0,d1,d2,d3,d4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>Reusando a função clean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean(doc):\n",
    "    doc = doc.lower()\n",
    "    doc = doc.replace('.',' ')\n",
    "    doc = doc.replace('-', ' ')\n",
    "    doc = doc.replace(',',' ')\n",
    "    doc = doc.replace('?',' ')\n",
    "    doc = doc.replace(')',' ')\n",
    "    doc = doc.replace('(',' ')\n",
    "    \n",
    "    doc = doc.replace(' the ',' ')\n",
    "    doc = doc.replace(' of ',' ')\n",
    "    doc = doc.replace(' is ',' ')\n",
    "    doc = doc.replace(' and ',' ')\n",
    "    doc = doc.replace(' a ',' ')\n",
    "    doc = doc.replace(' on ',' ')\n",
    "    doc = doc.replace(' by ',' ')\n",
    "    doc = doc.replace(' in ',' ')\n",
    "    doc = doc.replace(' for ',' ')\n",
    "    doc = doc.replace(' it ',' ')\n",
    "    doc = doc.replace(' as ',' ')\n",
    "    \n",
    "    for _ in range(10):\n",
    "        doc = doc.replace('  ',' ')\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import stop_words\n",
    "\n",
    "def clean2(doc):\n",
    "    for word in doc.split():\n",
    "        if word in stop_words.ENGLISH_STOP_WORDS:\n",
    "            doc = doc.replace(' '+word+' ',' ')\n",
    "    return doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_matrix(corpus, clean_fn):\n",
    "    matrix = {}\n",
    "    for idx,doc in enumerate(corpus):\n",
    "        \n",
    "        doc = clean_fn(doc)\n",
    "        \n",
    "        for term in doc.split():\n",
    "            if not matrix.get(term):\n",
    "                matrix[term] = [0] * len(corpus)\n",
    "            matrix[term][idx] = matrix[term][idx] + 1\n",
    "    return matrix.keys(), matrix.values()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run(corpus, clean_fn):\n",
    "    feature_names, df_matrix = make_matrix(corpus, clean_fn)\n",
    "\n",
    "    R = numpy.array(df_matrix)\n",
    "    N = len(R)\n",
    "    M = len(R[0])\n",
    "    K = 3\n",
    "    n_top_words = 20\n",
    "\n",
    "    P = numpy.random.rand(N,K)\n",
    "    Q = numpy.random.rand(M,K)\n",
    "\n",
    "    print 'P:',P.shape\n",
    "    print 'Q:',Q.shape\n",
    "    print 'palavras', len(feature_names)\n",
    "    nP, nQ = matrix_factorization(R, P, Q, K)\n",
    "\n",
    "    print 'components shape: ', nP.shape\n",
    "\n",
    "\n",
    "    for idx,topic in enumerate(nP.T):\n",
    "        print '\\nTópico', idx\n",
    "\n",
    "        tmp = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        for word_idx in tmp:\n",
    "            print feature_names[word_idx],\n",
    "        print '\\n'\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: (306, 3)\n",
      "Q: (5, 3)\n",
      "palavras 306\n",
      "components shape:  (306, 3)\n",
      "\n",
      "Tópico 0\n",
      "are species to smith writers descended jeff may hind were consensus engineered during record skeletons manufacturing fossilization includes discontinued projections \n",
      "\n",
      "\n",
      "Tópico 1\n",
      "python this dated to come concerns reticulatus colt where &amp; modern crop some nonvenomous boa nightmare 7 california approximately cultivated \n",
      "\n",
      "\n",
      "Tópico 2\n",
      "python tv sometimes region ninjas 1955 possess manufacturing other like years record introduced terrasanctus street also ago in 2000 segment \n",
      "\n"
     ]
    }
   ],
   "source": [
    "run(corpus1, clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: (4261, 3)\n",
      "Q: (30, 3)\n",
      "palavras 4261\n",
      "components shape:  (4261, 3)\n",
      "\n",
      "Tópico 0\n",
      "to edu graphics mail from or ray with 3d gm you [128 1 send ftp are this : also objects \n",
      "\n",
      "\n",
      "Tópico 1\n",
      "key at gm that not * torrey i mormon was we keys myself 3d session u msg back he repeat \n",
      "\n",
      "\n",
      "Tópico 2\n",
      "to edu graphics you mail gm [128 ray send or at from 3d with this that : ftp rayshade are \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "corpus2 = dataset.data[:30]\n",
    "\n",
    "run(corpus2, clean)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
